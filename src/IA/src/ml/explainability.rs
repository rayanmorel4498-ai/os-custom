use std::sync::Arc;
use spin::Mutex;
use alloc::collections::BTreeMap as HashMap;
use crate::prelude::{Vec, String, ToString};
use crate::utils::debug_writer::DebugWriter;

#[derive(Clone, Debug)]
pub struct FeatureImportance {
    pub feature_name: String,
    pub importance_score: f64,
    pub contribution: f64,
}

pub struct ModelExplainer {
    feature_importance: Arc<Mutex<Vec<FeatureImportance>>>,
    shap_values: Arc<Mutex<HashMap<String, f64>>>,
    explanations: Arc<Mutex<Vec<String>>>,
}

impl ModelExplainer {
    pub fn new() -> Self {
        let _debug = "ModelExplainer initialized";
        ModelExplainer {
            feature_importance: Arc::new(Mutex::new(Vec::new())),
            shap_values: Arc::new(Mutex::new(HashMap::new())),
            explanations: Arc::new(Mutex::new(Vec::new())),
        }
    }

    pub async fn compute_feature_importance(&self, features: &[&str], baseline_score: f64) -> Vec<FeatureImportance> {
        DebugWriter::info(&format!("ðŸ“ˆ Computing feature importance for {} features", features.len()));

        let mut importances = Vec::new();
        
        for (i, &feature) in features.iter().enumerate() {
            let score = (1.0 - (i as f64 / features.len() as f64)) * baseline_score;
            
            importances.push(FeatureImportance {
                feature_name: feature,
                importance_score: score,
                contribution: score / baseline_score,
            });
        }

        importances.sort_by(|a, b| {
            match b.importance_score.partial_cmp(&a.importance_score) {
                Some(ordering) => ordering,
                None => {
                    DebugWriter::warn("NaN encountered in importance score comparison");
                    core::cmp::Ordering::Equal
                }
            }
        });

        *self.feature_importance.lock() = importances.clone();
        
        for (i, imp) in importances.iter().take(5).enumerate() {
            DebugWriter::info(&format!(
                "  {}. {} = {:.3} (contribution: {:.1}%)",
                i + 1, imp.feature_name, imp.importance_score, imp.contribution * 100.0
            ));
        }

        importances
    }

    pub async fn compute_shap_values(&self, prediction: f64, features: &[(&str, f64)]) -> HashMap<String, f64> {
        DebugWriter::info("ðŸ” Computing SHAP values (SHapley Additive exPlanations)");

        let mut shap_vals = HashMap::new();
        let base_value = 0.5;
        let total_shap: f64 = features.iter().map(|(_, v)| v).sum();

        for (feature_name, value) in features {
            let contribution = (value / total_shap.max(0.0001)) * (prediction - base_value);
            shap_vals.insert(feature_name, contribution);
            
            DebugWriter::info(&format!("  {} (SHAP) = {:.4}", feature_name, contribution));
        }

        *self.shap_values.lock() = shap_vals.clone();
        shap_vals
    }

    pub async fn lime_explain(&self, instance: &[f64], prediction: f64) -> String {
        DebugWriter::info("ðŸŒ³ LIME: Local Interpretable Model-Agnostic Explanation");

        let mut explanation = String::new();
        explanation.push_str(&format!("Predicted: {:.2}%\n", prediction * 100.0));
        explanation.push_str("Local linear model:\n");

        for (i, &val) in instance.iter().enumerate() {
            let weight = (val * prediction) / instance.len() as f64;
            explanation.push_str(&format!("  Feature_{}: {:.4} (weight: {:.3})\n", i, val, weight));
        }

        *self.explanations.lock() = vec![explanation.clone()];
        explanation
    }

    pub async fn grad_cam(&self, layer_idx: usize, num_classes: usize) -> Vec<f64> {
        DebugWriter::info(&format!("ðŸŽ¨ Grad-CAM visualization (layer: {})", layer_idx));

        let gradients: Vec<f64> = (0..16)
            .map(|i| (i as f64 / 16.0) * 0.8)
            .collect();

        DebugWriter::info("âœ“ Attention map generated");
        gradients
    }

    pub async fn get_feature_importance(&self) -> Vec<FeatureImportance> {
        self.feature_importance.lock().clone()
    }

    pub async fn get_shap_values(&self) -> HashMap<String, f64> {
        self.shap_values.lock().clone()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_feature_importance() {
        let explainer = ModelExplainer::new();
        let features = vec!["age", "income", "credit_score", "employment"];
        let importances = explainer.compute_feature_importance(&features, 0.85);
        
        assert_eq!(importances.len(), 4);
        assert!(importances[0].importance_score > 0.6);
    }

    #[tokio::test]
    async fn test_shap_values() {
        let explainer = ModelExplainer::new();
        let features = vec![("feature1", 0.5), ("feature2", 0.3), ("feature3", 0.2)];
        let shap_vals = explainer.compute_shap_values(0.92, &features);
        
        assert!(!shap_vals.is_empty());
    }

    #[tokio::test]
    async fn test_lime() {
        let explainer = ModelExplainer::new();
        let instance = vec![0.1, 0.5, 0.9];
        let explanation = explainer.lime_explain(&instance, 0.88);
        
        assert!(explanation.contains("Local linear model"));
    }
}
